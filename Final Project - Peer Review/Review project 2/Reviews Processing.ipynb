{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"yelp/yelp_academic_dataset_review.json\") as data_file:   \n",
    "    data = data_file.readlines()\n",
    "data_json_str = \"[\" + ','.join(data) + \"]\"\n",
    "reviews = pd.read_json(data_json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"yelp/yelp_academic_dataset_business.json\") as data_file:   \n",
    "    data = data_file.readlines()\n",
    "data_json_str = \"[\" + ','.join(data) + \"]\"\n",
    "\n",
    "business = pd.read_json(data_json_str)\n",
    "def get_rest(r):\n",
    "    try:\n",
    "        return \"Restaurants\" in r[\"categories\"]\n",
    "    except:\n",
    "        return False\n",
    "restaurants = business.loc[business.apply(get_rest,axis=1),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "useless_cols = [\"type\",\"date\",\"review_id\",\"user_id\"]\n",
    "reviews.drop(useless_cols,axis=1,inplace=True)\n",
    "useful_reviews = reviews.loc[reviews.useful>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "restaurants = restaurants.loc[~pd.isnull(restaurants.business_id)]\n",
    "useful_reviews = useful_reviews.loc[~pd.isnull(useful_reviews.business_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "useful_rest_reviews = pd.merge(useful_reviews,restaurants,how=\"inner\",on = \"business_id\")\n",
    "useful_rest_reviews = useful_rest_reviews[[\"cool\",\"funny\",\"stars_x\",\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_indx = useful_rest_reviews.stars_x==1\n",
    "bad_indx.append(useful_rest_reviews.stars_x==2)\n",
    "good_reviews = useful_rest_reviews.loc[useful_rest_reviews.stars_x==5]\n",
    "bad_reviews = useful_rest_reviews.loc[bad_indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'cool', u'funny', u'stars_x', u'text']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_reviews_sample = good_reviews.sample(10000)\n",
    "bad_reviews_sample = bad_reviews.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "p_stemmer = PorterStemmer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def stem_words(com):\n",
    "    # tokenize\n",
    "    tokens = tokenizer.tokenize(com)\n",
    "    \n",
    "    stemmed = [p_stemmer.stem(t) for t in tokens]\n",
    "    \n",
    "    return ' '.join(stemmed)\n",
    "\n",
    "\n",
    "stemmed_good_reviews = [stem_words(review) for review in good_reviews_sample.text]\n",
    "stemmed_bad_reviews = [stem_words(review) for review in bad_reviews_sample.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 126)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",tokenizer = None,preprocessor = None, min_df=.008,max_df=.5,ngram_range=(2,2),\n",
    "                             stop_words = \"english\") \n",
    "\n",
    "word_feature_list = vectorizer.fit_transform(good_reviews_sample.text)\n",
    "word_features = pd.DataFrame(word_feature_list.toarray())\n",
    "print(word_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_features.columns = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_counts = word_features.apply(sum,axis=0)\n",
    "word_counts.head()\n",
    "word_counts.columns = \"Word Count\"\n",
    "word_counts.to_csv(\"good_reviews.csv\",encoding=\"utf-8\",index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 161)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",tokenizer = None,preprocessor = None, min_df=.008,max_df=.5,ngram_range=(2,2),\n",
    "                             stop_words = \"english\") \n",
    "\n",
    "word_feature_list = vectorizer.fit_transform(bad_reviews_sample.text)\n",
    "word_features = pd.DataFrame(word_feature_list.toarray())\n",
    "print(word_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'10 minutes', u'15 minutes', u'20 minutes', u'25 minutes', u'30 minutes', u'40 minutes', u'45 minutes', u'asked manager', u'asked wanted', u'avoid place', u'bad experience', u'bad food', u'bad service', u'better food', u'better service', u'big deal', u'came asked', u'came said', u'came table', u'chinese food', u'chips salsa', u'credit card', u'customer service', u'decided try', u'did come', u'didn bother', u'didn care', u'didn eat', u'didn know', u'didn like', u'didn want', u'dining experience', u'dining room', u'don care', u'don know', u'don like', u'don think', u'don want', u'don waste', u'drink order', u'excited try', u'extremely rude', u'far worst', u'fast food', u'feel like', u'felt like', u'finally came', u'finally got', u'food arrived', u'food bad', u'food came', u'food cold', u'food food', u'food good', u'food great', u'food horrible', u'food just', u'food mediocre', u'food ok', u'food order', u'food ordered', u'food place', u'food poisoning', u'food quality', u'food service', u'food terrible', u'food took', u'food wasn', u'friday night', u'fried rice', u'good food', u'good service', u'good thing', u'got food', u'got home', u'great food', u'great service', u'half hour', u'happy hour', u'horrible experience', u'horrible service', u'hour half', u'ice cream', u'just got', u'just left', u'just wanted', u'las vegas', u'let know', u'like place', u'long time', u'long wait', u'look like', u'looked like', u'looking forward', u'looks like', u'mac cheese', u'make sure', u'manager came', u'mediocre best', u'mediocre food', u'mexican food', u'minute wait', u'minutes food', u'minutes later', u'needless say', u'order food', u'order wrong', u'ordered chicken', u'ordered food', u'parking lot', u'place just', u'place like', u'place order', u'placed order', u'poor service', u'pretty good', u'quality food', u'really bad', u'really good', u'really wanted', u'recommend place', u'right away', u'sat bar', u'saturday night', u'save money', u'second time', u'server came', u'service bad', u'service food', u'service good', u'service horrible', u'service slow', u'service terrible', u'slow service', u'speak manager', u'stay away', u'sub par', u'taste like', u'tasted like', u'tastes like', u'terrible service', u'time food', u'time got', u'time money', u'time went', u'took forever', u'took order', u'try place', u've eaten', u've seen', u'wait staff', u'walked away', u'wanted try', u'waste money', u'waste time', u'won going', u'worst experience', u'worst service', u'year old', u'years ago', u'zero stars']\n"
     ]
    }
   ],
   "source": [
    "print vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_features.columns = vectorizer.get_feature_names()\n",
    "word_counts = word_features.apply(sum,axis=0)\n",
    "word_counts.head()\n",
    "word_counts.columns = \"Word Count\"\n",
    "word_counts.to_csv(\"bad_reviews.csv\",encoding=\"utf-8\",index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
